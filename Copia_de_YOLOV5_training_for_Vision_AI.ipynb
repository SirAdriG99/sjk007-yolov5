{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wCnaloE6aew"
      },
      "source": [
        "This notebook will guide you to train your own AI model using YOLOv5!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VrcRq-U6G2v"
      },
      "source": [
        "**Step 1.** Choose **GPU** in **Runtime** if not already selected by navigating to `Runtime --> Change Runtime Type --> Hardware accelerator --> GPU`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8prsdf8u8Mv"
      },
      "source": [
        "**Step 2.** Clone repo, install dependencies and check PyTorch and GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfnLgOjgu8ng",
        "outputId": "583615e3-a29e-4ab5-8a8b-85c745ce0147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov5-swift'...\n",
            "remote: Enumerating objects: 9424, done.\u001b[K\n",
            "remote: Total 9424 (delta 0), reused 0 (delta 0), pack-reused 9424\u001b[K\n",
            "Receiving objects: 100% (9424/9424), 22.32 MiB | 12.74 MiB/s, done.\n",
            "Resolving deltas: 100% (6309/6309), done.\n",
            "/content/yolov5-swift\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSetup complete. Using torch 2.1.0+cu121 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15102MB, multi_processor_count=40)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SirAdriG99/sjk007-yolov5  # clone\n",
        "%cd yolov5-swift\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from google.colab import files\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPagIdHSaY6n"
      },
      "source": [
        "**Step 3.** Set up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C32Eow5zafe_"
      },
      "outputs": [],
      "source": [
        "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbUvo-BXefbu"
      },
      "source": [
        "**Step 4.** Copy and paste the displayed code snippet from Roboflow on to the code cell below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmJjFIEpfF44"
      },
      "source": [
        "<div align=center><img width=500 src=\"https://files.seeedstudio.com/wiki/YOLOV5/81.png\"/></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2su7XslvY4S1",
        "outputId": "e0efe89a-4dfc-4490-b318-42d6d5bbf311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.19-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.2/70.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Collecting supervision (from roboflow)\n",
            "  Downloading supervision-0.18.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.49.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (0.7.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n",
            "Installing collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.9.0.80\n",
            "    Uninstalling opencv-python-headless-4.9.0.80:\n",
            "      Successfully uninstalled opencv-python-headless-4.9.0.80\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.2.2\n",
            "    Uninstalling certifi-2024.2.2:\n",
            "      Successfully uninstalled certifi-2024.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.19 supervision-0.18.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "cycler"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in /content/datasets/SJK007-1 to yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 528474/528474 [00:30<00:00, 17117.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to /content/datasets/SJK007-1 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16054/16054 [00:03<00:00, 5015.61it/s]\n"
          ]
        }
      ],
      "source": [
        "#copy and paste the code here and make sure it follows the same format as below.\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"wnyNNJVRwmHJTNTGJpWz\")\n",
        "project = rf.workspace(\"al397463\").project(\"sjk007\")\n",
        "dataset = project.version(1).download(\"yolov5\")\n",
        "\n",
        "#!pip install roboflow\n",
        "#from roboflow import Roboflow\n",
        "#rf = Roboflow(api_key=\"YOUR API KEY HERE\")\n",
        "#project = rf.workspace().project(\"YOUR PROJECT\")\n",
        "#dataset = project.version(\"YOUR VERSION\").download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg4hIoyzE-Qe",
        "outputId": "58127cb9-455e-4ad8-fedf-cb156a17e6a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "names:\n",
            "- bad road\n",
            "- car\n",
            "- chair\n",
            "- door\n",
            "- drain\n",
            "- fence\n",
            "- garbage bin\n",
            "- gate barrier\n",
            "- left turn\n",
            "- motorcycle\n",
            "- obstacle\n",
            "- pedestrian\n",
            "- plant pot\n",
            "- pole\n",
            "- pothole\n",
            "- puddle\n",
            "- right turn\n",
            "- roadblock\n",
            "- stair\n",
            "- street vendor\n",
            "- tree\n",
            "- zebra cross\n",
            "nc: 22\n",
            "roboflow:\n",
            "  license: MIT\n",
            "  project: sjk007\n",
            "  url: https://universe.roboflow.com/al397463/sjk007/dataset/1\n",
            "  version: 1\n",
            "  workspace: al397463\n",
            "test: ../test/images\n",
            "train: /content/datasets/SJK007-1/train/images\n",
            "val: /content/datasets/SJK007-1/valid/images\n"
          ]
        }
      ],
      "source": [
        "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "%cat {dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX1U12sNFRM5"
      },
      "source": [
        "**Step 5.** Download a pre-trained model suitable for our training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db3JVwsPFp5R",
        "outputId": "14c18f79-bb48-4648-d825-cb9804afd426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-26 14:19:10--  https://github.com/Seeed-Studio/yolov5-swift/releases/download/v0.1.0-alpha/yolov5n6-xiao.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/483523906/2e3a41ce-abc0-446a-9573-1173f4e58024?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240226%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240226T141910Z&X-Amz-Expires=300&X-Amz-Signature=d0e4c4a175a9351c398941324b9a9f4e7f2fc2912939dfe2ac6fc3560b628621&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=483523906&response-content-disposition=attachment%3B%20filename%3Dyolov5n6-xiao.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-02-26 14:19:10--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/483523906/2e3a41ce-abc0-446a-9573-1173f4e58024?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240226%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240226T141910Z&X-Amz-Expires=300&X-Amz-Signature=d0e4c4a175a9351c398941324b9a9f4e7f2fc2912939dfe2ac6fc3560b628621&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=483523906&response-content-disposition=attachment%3B%20filename%3Dyolov5n6-xiao.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1293269 (1.2M) [application/octet-stream]\n",
            "Saving to: â€˜yolov5n6-xiao.ptâ€™\n",
            "\n",
            "yolov5n6-xiao.pt    100%[===================>]   1.23M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-02-26 14:19:11 (111 MB/s) - â€˜yolov5n6-xiao.ptâ€™ saved [1293269/1293269]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/Seeed-Studio/yolov5-swift/releases/download/v0.1.0-alpha/yolov5n6-xiao.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDBfSV8exwbe"
      },
      "source": [
        "**Step 6.** Start training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6_oEXQqG8B6"
      },
      "source": [
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs\n",
        "- **data:** set the path to our yaml file\n",
        "- **cfg:** specify our model configuration\n",
        "- **weights:** specify a custom path to weights\n",
        "- **name:** result names\n",
        "- **nosave:** only save the final checkpoint\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCzjlGRSzs_F",
        "outputId": "e34bf872-1d17-46a0-d867-761368c3f3d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-02-26 14:29:02.891378: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5n6-xiao.pt, cfg=yolov5n6-xiao.yaml, data=/content/datasets/SJK007-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=64, imgsz=192, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5n6_results, exist_ok=False, quad=False, two_linear_lr=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/Seeed-Studio/yolov5-swif âœ…\n",
            "YOLOv5 ðŸš€ v0.1.0-alpha-20-gc0abd26 torch 2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=22\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       880  models.common.Conv                      [3, 8, 6, 2, 2]               \n",
            "  1                -1  1      1184  models.common.Conv                      [8, 16, 3, 2]                 \n",
            "  2                -1  1      1248  models.common.C3                        [16, 16, 1]                   \n",
            "  3                -1  1      3504  models.common.Conv                      [16, 24, 3, 2]                \n",
            "  4                -1  2      4224  models.common.C3                        [24, 24, 2]                   \n",
            "  5                -1  1     10464  models.common.Conv                      [24, 48, 3, 2]                \n",
            "  6                -1  3     22368  models.common.C3                        [48, 48, 3]                   \n",
            "  7                -1  1     31248  models.common.Conv                      [48, 72, 3, 2]                \n",
            "  8                -1  1     23760  models.common.C3                        [72, 72, 1]                   \n",
            "  9                -1  1     62400  models.common.Conv                      [72, 96, 3, 2]                \n",
            " 10                -1  1     42048  models.common.C3                        [96, 96, 1]                   \n",
            " 11                -1  1     23328  models.common.SPPF                      [96, 96, 5]                   \n",
            " 12                -1  1      7056  models.common.Conv                      [96, 72, 1, 1]                \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  1     28944  models.common.C3                        [144, 72, 1, False]           \n",
            " 16                -1  1      3552  models.common.Conv                      [72, 48, 1, 1]                \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1     12960  models.common.C3                        [96, 48, 1, False]            \n",
            " 20                -1  1      1200  models.common.Conv                      [48, 24, 1, 1]                \n",
            " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1      3312  models.common.C3                        [48, 24, 1, False]            \n",
            " 24                -1  1      5232  models.common.Conv                      [24, 24, 3, 2]                \n",
            " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1     10656  models.common.C3                        [48, 48, 1, False]            \n",
            " 27                -1  1     20832  models.common.Conv                      [48, 48, 3, 2]                \n",
            " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
            " 29                -1  1     25488  models.common.C3                        [96, 72, 1, False]            \n",
            " 30                -1  1     46800  models.common.Conv                      [72, 72, 3, 2]                \n",
            " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 32                -1  1     46656  models.common.C3                        [144, 96, 1, False]           \n",
            " 33  [23, 26, 29, 32]  1     19764  models.yolo.Detect                      [22, [[9, 12, 21, 18, 17, 41], [40, 32, 38, 73, 86, 57], [69, 120, 144, 123, 109, 240], [331, 182, 216, 326, 467, 375]], [24, 48, 72, 96]]\n",
            "Model Summary: 356 layers, 459108 parameters, 459108 gradients, 0.9 GFLOPs\n",
            "\n",
            "Transferred 450/459 items from yolov5n6-xiao.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 75 weight (no decay), 79 weight, 79 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/datasets/SJK007-1/train/labels.cache' images and labels... 7020 found, 0 missing, 0 empty, 0 corrupt: 100% 7020/7020 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100% 7020/7020 [00:38<00:00, 181.95it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/SJK007-1/valid/labels.cache' images and labels... 668 found, 0 missing, 0 empty, 0 corrupt: 100% 668/668 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 668/668 [00:06<00:00, 96.31it/s] \n",
            "Plotting labels to runs/train/yolov5n6_results4/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.69 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Image sizes 192 train, 192 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov5n6_results4\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/99    0.505G    0.1053   0.01354   0.08078       126       192: 100% 110/110 [00:34<00:00,  3.21it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:07<00:00,  1.18s/it]\n",
            "                 all        668       1080   0.000402     0.0775   0.000301    6.8e-05\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/99    0.505G   0.08338   0.01513   0.07216       126       192: 100% 110/110 [00:25<00:00,  4.29it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:05<00:00,  1.08it/s]\n",
            "                 all        668       1080      0.879     0.0094     0.0103    0.00273\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/99    0.505G   0.07588   0.01475   0.06931       165       192: 100% 110/110 [00:24<00:00,  4.56it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:05<00:00,  1.12it/s]\n",
            "                 all        668       1080      0.518      0.088     0.0227    0.00602\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/99    0.505G   0.07273   0.01456   0.06625       106       192: 100% 110/110 [00:26<00:00,  4.14it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:05<00:00,  1.18it/s]\n",
            "                 all        668       1080      0.948     0.0367     0.0323     0.0121\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/99    0.505G   0.07046   0.01462   0.06299       139       192: 100% 110/110 [00:25<00:00,  4.29it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:04<00:00,  1.31it/s]\n",
            "                 all        668       1080      0.956     0.0308     0.0359     0.0121\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/99    0.505G   0.06928   0.01435   0.06122       156       192: 100% 110/110 [00:25<00:00,  4.33it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:05<00:00,  1.04it/s]\n",
            "                 all        668       1080      0.944     0.0419     0.0486     0.0153\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/99    0.505G    0.0677   0.01433    0.0599       121       192: 100% 110/110 [00:25<00:00,  4.25it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.71it/s]\n",
            "                 all        668       1080      0.843     0.0598     0.0697     0.0239\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/99    0.505G   0.06716    0.0143   0.05855       128       192: 100% 110/110 [00:26<00:00,  4.12it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "                 all        668       1080      0.764     0.0847     0.0785     0.0264\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/99    0.505G    0.0664   0.01418   0.05731       130       192: 100% 110/110 [00:26<00:00,  4.10it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "                 all        668       1080      0.692     0.0945     0.0745     0.0241\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/99    0.505G   0.06593   0.01409   0.05657       126       192: 100% 110/110 [00:26<00:00,  4.22it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "                 all        668       1080      0.866     0.0975      0.105     0.0388\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/99    0.505G   0.06546   0.01398   0.05569       130       192: 100% 110/110 [00:26<00:00,  4.21it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:04<00:00,  1.43it/s]\n",
            "                 all        668       1080       0.81     0.0797     0.0799     0.0293\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/99    0.505G   0.06536   0.01408    0.0543       125       192: 100% 110/110 [00:26<00:00,  4.13it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.50it/s]\n",
            "                 all        668       1080       0.75      0.108      0.114     0.0453\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/99    0.505G   0.06524   0.01401   0.05345       124       192: 100% 110/110 [00:26<00:00,  4.19it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.85it/s]\n",
            "                 all        668       1080      0.834     0.0981      0.115     0.0436\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/99    0.505G   0.06487   0.01381   0.05255       126       192: 100% 110/110 [00:26<00:00,  4.13it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.77it/s]\n",
            "                 all        668       1080      0.562      0.145      0.136     0.0487\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/99    0.505G   0.06438   0.01393   0.05223       159       192: 100% 110/110 [00:26<00:00,  4.20it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:04<00:00,  1.36it/s]\n",
            "                 all        668       1080      0.848      0.121      0.145     0.0599\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     15/99    0.505G   0.06402   0.01394   0.05113       150       192: 100% 110/110 [00:25<00:00,  4.30it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:04<00:00,  1.28it/s]\n",
            "                 all        668       1080      0.866      0.108      0.148     0.0597\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     16/99    0.505G   0.06411   0.01394   0.05095       127       192: 100% 110/110 [00:27<00:00,  4.07it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.75it/s]\n",
            "                 all        668       1080      0.673       0.12      0.117      0.044\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     17/99    0.505G   0.06369   0.01376   0.05017       131       192: 100% 110/110 [00:25<00:00,  4.29it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.76it/s]\n",
            "                 all        668       1080      0.385      0.217      0.173     0.0644\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     18/99    0.505G   0.06343   0.01377   0.04905       141       192: 100% 110/110 [00:27<00:00,  4.03it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:04<00:00,  1.38it/s]\n",
            "                 all        668       1080      0.892       0.13      0.197     0.0693\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     19/99    0.505G   0.06325   0.01379   0.04961       126       192: 100% 110/110 [00:25<00:00,  4.29it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                 all        668       1080      0.331      0.253      0.192     0.0725\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     20/99    0.505G   0.06336   0.01357   0.04899       117       192: 100% 110/110 [00:26<00:00,  4.20it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.98it/s]\n",
            "                 all        668       1080      0.395      0.177      0.159     0.0653\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     21/99    0.505G   0.06259   0.01365   0.04823       155       192: 100% 110/110 [00:26<00:00,  4.22it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.80it/s]\n",
            "                 all        668       1080      0.691      0.177       0.18     0.0688\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     22/99    0.505G   0.06286   0.01387   0.04818       124       192: 100% 110/110 [00:25<00:00,  4.29it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.82it/s]\n",
            "                 all        668       1080      0.551      0.203        0.2     0.0761\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     23/99    0.505G   0.06271   0.01376   0.04742       132       192: 100% 110/110 [00:25<00:00,  4.33it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.74it/s]\n",
            "                 all        668       1080      0.721      0.157      0.185     0.0672\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     24/99    0.505G   0.06215   0.01372   0.04721       111       192: 100% 110/110 [00:25<00:00,  4.33it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:04<00:00,  1.50it/s]\n",
            "                 all        668       1080      0.494      0.225      0.178     0.0659\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     25/99    0.505G   0.06248   0.01361   0.04713       137       192: 100% 110/110 [00:25<00:00,  4.30it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.51it/s]\n",
            "                 all        668       1080       0.73      0.216      0.247      0.098\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     26/99    0.505G   0.06193   0.01356   0.04654       109       192: 100% 110/110 [00:27<00:00,  4.06it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.85it/s]\n",
            "                 all        668       1080      0.665      0.226      0.229     0.0929\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     27/99    0.505G   0.06163   0.01373   0.04592       139       192: 100% 110/110 [00:27<00:00,  4.05it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.84it/s]\n",
            "                 all        668       1080      0.391       0.29      0.228     0.0876\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     28/99    0.505G   0.06182   0.01359   0.04555       168       192: 100% 110/110 [00:25<00:00,  4.23it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.80it/s]\n",
            "                 all        668       1080      0.376      0.306      0.235     0.0932\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     29/99    0.505G   0.06145   0.01365   0.04544       107       192: 100% 110/110 [00:25<00:00,  4.36it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "                 all        668       1080      0.695      0.202      0.241     0.0973\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     30/99    0.505G   0.06174   0.01345   0.04549       146       192: 100% 110/110 [00:24<00:00,  4.58it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "                 all        668       1080      0.726      0.229      0.261     0.0994\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     31/99    0.505G   0.06108    0.0135   0.04506       146       192: 100% 110/110 [00:25<00:00,  4.32it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.67it/s]\n",
            "                 all        668       1080      0.631       0.24      0.262      0.104\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     32/99    0.505G   0.06134   0.01335   0.04498       107       192: 100% 110/110 [00:25<00:00,  4.26it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.90it/s]\n",
            "                 all        668       1080       0.75      0.219      0.261      0.106\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     33/99    0.505G   0.06107   0.01354   0.04458       134       192: 100% 110/110 [00:26<00:00,  4.17it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.84it/s]\n",
            "                 all        668       1080      0.659      0.226      0.233     0.0999\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     34/99    0.505G     0.061   0.01352   0.04457       155       192: 100% 110/110 [00:26<00:00,  4.12it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.94it/s]\n",
            "                 all        668       1080      0.528      0.276      0.272      0.107\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     35/99    0.505G    0.0613   0.01351   0.04419       111       192: 100% 110/110 [00:26<00:00,  4.16it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:04<00:00,  1.50it/s]\n",
            "                 all        668       1080      0.492      0.307      0.273       0.11\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     36/99    0.505G   0.06085   0.01343    0.0438       150       192: 100% 110/110 [00:26<00:00,  4.08it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0% 0/6 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "!python3 train.py --img 192 --batch 64 --epochs 100 --data {dataset.location}/data.yaml --cfg yolov5n6-xiao.yaml --weights yolov5n6-xiao.pt --name yolov5n6_results --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpmLzJJ6M6_m"
      },
      "source": [
        "**Step 7.** Export TensorFlow Lite file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY8GOqDKM41s",
        "outputId": "0919bbca-3564-4fe6-90d5-887b04d63665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=/content/datasets/SJK007-1/data.yaml, weights=['runs/train/yolov5n6_results/weights/best.pt'], imgsz=[192], batch_size=1, device=cpu, half=False, inplace=False, train=False, optimize=False, int8=True, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, nms_head=6, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['tflite']\n",
            "YOLOv5 ðŸš€ v0.1.0-alpha-20-gc0abd26 torch 2.1.0+cu121 CPU\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5-swift/export.py\", line 562, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5-swift/export.py\", line 557, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5-swift/export.py\", line 448, in run\n",
            "    model = attempt_load(weights, map_location=device, inplace=True, fuse=True)  # load FP32 model\n",
            "  File \"/content/yolov5-swift/models/experimental.py\", line 96, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location=map_location)  # load\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 986, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 435, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 416, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'runs/train/yolov5n6_results/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "!python3 export.py --data {dataset.location}/data.yaml --weights runs/train/yolov5n6_results/weights/best.pt --imgsz 192 --int8 --include tflite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfbD2N2eMkV3"
      },
      "source": [
        "**Step 8.** Convert TensorFlow Lite to UF2 file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtpBb33HkSC7"
      },
      "source": [
        "UF2 is a file format, developed by Microsoft. Seeed uses this format to convert .tflite to .uf2, allowing tflite files to be stored on the AIoT devices launched by Seeed. Currently Seeed's devices support up to 4 models, each model (.tflite) is less than 1M .\n",
        "\n",
        "You can specify the model to be placed in the corresponding index with -t.\n",
        "\n",
        "For example:\n",
        "\n",
        "- `-t 1`: index 1\n",
        "- `-t 2`: index 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f3-VHKGNRTw"
      },
      "outputs": [],
      "source": [
        "# Place the model to index 1\n",
        "!python3 uf2conv.py -f GROVEAI -t 1 -c runs//train/yolov5n6_results//weights/best-int8.tflite -o model-1.uf2\n",
        "%cp model-1.uf2 ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8MXi72tNKJE"
      },
      "source": [
        "**Step 9.** Download the trained model file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61orx1ttMJoU"
      },
      "outputs": [],
      "source": [
        "files.download(\"/content/model-1.uf2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHDAOmaYNfc1"
      },
      "source": [
        "The above is the file that we will load into the SenseCAP A1101/ Grove - Vision AI Module to perform the inference!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
